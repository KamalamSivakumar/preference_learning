{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userAction</th>\n",
       "      <th>c1r</th>\n",
       "      <th>c1g</th>\n",
       "      <th>c1b</th>\n",
       "      <th>c2r</th>\n",
       "      <th>c2g</th>\n",
       "      <th>c2b</th>\n",
       "      <th>c3r</th>\n",
       "      <th>c3g</th>\n",
       "      <th>c3b</th>\n",
       "      <th>c4r</th>\n",
       "      <th>c4g</th>\n",
       "      <th>c4b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>dislike</td>\n",
       "      <td>193</td>\n",
       "      <td>19</td>\n",
       "      <td>59</td>\n",
       "      <td>185</td>\n",
       "      <td>86</td>\n",
       "      <td>143</td>\n",
       "      <td>250</td>\n",
       "      <td>55</td>\n",
       "      <td>218</td>\n",
       "      <td>152</td>\n",
       "      <td>113</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Like</td>\n",
       "      <td>38</td>\n",
       "      <td>154</td>\n",
       "      <td>243</td>\n",
       "      <td>21</td>\n",
       "      <td>189</td>\n",
       "      <td>124</td>\n",
       "      <td>107</td>\n",
       "      <td>103</td>\n",
       "      <td>118</td>\n",
       "      <td>63</td>\n",
       "      <td>156</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dislike</td>\n",
       "      <td>51</td>\n",
       "      <td>66</td>\n",
       "      <td>187</td>\n",
       "      <td>97</td>\n",
       "      <td>15</td>\n",
       "      <td>69</td>\n",
       "      <td>241</td>\n",
       "      <td>145</td>\n",
       "      <td>184</td>\n",
       "      <td>6</td>\n",
       "      <td>218</td>\n",
       "      <td>168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dislike</td>\n",
       "      <td>224</td>\n",
       "      <td>171</td>\n",
       "      <td>164</td>\n",
       "      <td>198</td>\n",
       "      <td>238</td>\n",
       "      <td>70</td>\n",
       "      <td>137</td>\n",
       "      <td>127</td>\n",
       "      <td>55</td>\n",
       "      <td>210</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Like</td>\n",
       "      <td>97</td>\n",
       "      <td>210</td>\n",
       "      <td>199</td>\n",
       "      <td>223</td>\n",
       "      <td>155</td>\n",
       "      <td>37</td>\n",
       "      <td>186</td>\n",
       "      <td>42</td>\n",
       "      <td>61</td>\n",
       "      <td>53</td>\n",
       "      <td>163</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  userAction  c1r  c1g  c1b  c2r  c2g  c2b  c3r  c3g  c3b  c4r  c4g  c4b\n",
       "0    dislike  193   19   59  185   86  143  250   55  218  152  113   12\n",
       "1       Like   38  154  243   21  189  124  107  103  118   63  156  217\n",
       "2    dislike   51   66  187   97   15   69  241  145  184    6  218  168\n",
       "3    dislike  224  171  164  198  238   70  137  127   55  210   11   49\n",
       "4       Like   97  210  199  223  155   37  186   42   61   53  163  242"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"heldig_data_user1.csv\")\n",
    "data = df.drop(['clickX', 'clickY'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad9dc611",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "access_token = \"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\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd6f51ca",
   "metadata": {},
   "source": [
    "### Level 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cf9084e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "system_prompt = (\n",
    "            \"\"\" You are part of the recommendations team. As a helpful assistant, aid in suggesting the colours for the wallpaper generator app, based on the user's preferences given. \"\"\"\n",
    ")\n",
    "assistant_prompt = (\n",
    "               \"\"\"Suggest new wallpaper colours for the user based on the given preferences. Apply the guidlines as mentioned below, do not hallucinate the answer.\"\"\"\n",
    "               \"\"\"The user preference is a table with their preferences denoted by like/dislike, and it is as follows: {preference}\"\"\"\n",
    "               \"\"\"\n",
    "               Guidelines:\n",
    "               1. Give a single colour combination output. Try not to give any already mentioned colour from the preference data.\n",
    "               3. The output should be given as follows: \n",
    "                    c1r : ## | c1g : ## | c1b: ## | respective colour name | respective colour hex-code\n",
    "                    c2r : ## | c2g : ## | c2b: ## | respective colour name | respective colour hex-code\n",
    "                    c3r : ## | c3g : ## | c3b: ## | respective colour name | respective colour hex-code\n",
    "                    c4r : ## | c4g : ## | c4b: ## | respective colour name | respective colour hex-code\n",
    "               4. Finally give a message suggesting a creative name for the wallpaper based on the colours said by you.\n",
    "               \"\"\"\n",
    "           )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "dc1a2009",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system_prompt),\n",
    "        (\"assistant\", assistant_prompt),\n",
    "        (\"human\", \"{preference}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8c0e1919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
      "Token is valid (permission: write).\n",
      "Your token has been saved to C:\\Users\\kamalam.s\\.cache\\huggingface\\token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from langchain_huggingface import HuggingFaceEndpoint\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain.evaluation import load_evaluator\n",
    "import langchain.evaluation\n",
    "import time\n",
    "\n",
    "model = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "llm = HuggingFaceEndpoint(repo_id=model , huggingfacehub_api_token = access_token, \n",
    "                            max_new_tokens=2000,\n",
    "                            top_k=50,\n",
    "                            top_p=0.99,\n",
    "                            temperature=0.1)\n",
    "\n",
    "def suggestion(prompt, pref, llm):\n",
    "    llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "    llm_reply = llm_chain.invoke({\"preference\":pref}) \n",
    "    pred = llm_reply['text'] ##llm answer\n",
    "    return pred, llm_reply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d31da452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time:  2.881115436553955 seconds \n",
      "\n"
     ]
    }
   ],
   "source": [
    "st = time.time()\n",
    "llm_answer, whole = suggestion(prompt, u3, llm)\n",
    "et = time.time()\n",
    "print(\"Elapsed time: \", et-st, \"seconds\", \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00351c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "AI: Based on the user's preferences, I suggest the following colour combination for the wallpaper:\n",
      "\n",
      "c1r: 240 | c1g: 240 | c1b: 150 | Light Gray | #F0F096\n",
      "c2r: 150 | c2g: 100 | c2b: 20 | Dark Olive Green | #966414\n",
      "c3r: 200 | c3g: 255 | c3b: 200 | Light Sky Blue | #C8FFFF\n",
      "c4r: 255 | c4g: 20 | c4b: 20 | Light Coral | #FF7F50\n",
      "\n",
      "Suggested creative name for the wallpaper: \"Olive Sky Coral Light\"\n"
     ]
    }
   ],
   "source": [
    "print(llm_answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84ce711",
   "metadata": {},
   "source": [
    "### Level 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c27fa3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random generated data is considered. Totally 5 users, 5 files hence.\n",
    "u1 = data\n",
    "\n",
    "user2 = pd.read_csv(\"heldig_data_user2.csv\")\n",
    "u2 = user2.drop(['sno'], axis=1)\n",
    "\n",
    "user3 = pd.read_csv(\"heldig_data_user3.csv\")\n",
    "u3 = user3.drop(['sno'], axis=1)\n",
    "\n",
    "user4 = pd.read_csv(\"heldig_data_user4.csv\")\n",
    "u4 = user4.drop(['sno'],axis=1)\n",
    "\n",
    "user5 = pd.read_csv(\"heldig_data_user5.csv\")\n",
    "u5 = user5.drop(['sno'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7523c296",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen = [u1.to_dict(), u2.to_dict(), u3.to_dict(), u4.to_dict, u5.to_dict()]\n",
    "prompts = [\n",
    "    \"\"\" You are part of the recommendations team. As a helpful assistant, aid in suggesting the colours for the wallpaper generator app, based on the user's preferences given. \"\"\"\n",
    "    \"\"\"Suggest new wallpaper colours for the user based on the given preferences. Apply the guidlines as mentioned below, do not hallucinate the answer.\"\"\"\n",
    "    \"\"\"The user preference is a table with their preferences denoted by like/dislike, and it is as follows:    userAction  c1r  c1g  c1b  c2r  c2g  c2b  c3r  c3g  c3b  c4r  c4g  c4b\n",
    "0     dislike  193   19   59  185   86  143  250   55  218  152  113   12\n",
    "1        Like   38  154  243   21  189  124  107  103  118   63  156  217\n",
    "2     dislike   51   66  187   97   15   69  241  145  184    6  218  168\n",
    "3     dislike  224  171  164  198  238   70  137  127   55  210   11   49\n",
    "4        Like   97  210  199  223  155   37  186   42   61   53  163  242\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Guidelines:\n",
    "    1. Give a single colour combination output. Try not to give any already mentioned colour from the preference data.\n",
    "    3. The output should be given as follows: \n",
    "        c1r : ## | c1g : ## | c1b: ## | respective colour name | respective colour hex-code\n",
    "        c2r : ## | c2g : ## | c2b: ## | respective colour name | respective colour hex-code\n",
    "        c3r : ## | c3g : ## | c3b: ## | respective colour name | respective colour hex-code\n",
    "        c4r : ## | c4g : ## | c4b: ## | respective colour name | respective colour hex-code\n",
    "    4. Finally give a message suggesting a creative name for the wallpaper based on the colours said by you.\n",
    "    \"\"\",\n",
    "\n",
    "        \"\"\" You are part of the recommendations team. As a helpful assistant, aid in suggesting the colours for the wallpaper generator app, based on the user's preferences given. \"\"\"\n",
    "    \"\"\"Suggest new wallpaper colours for the user based on the given preferences. Apply the guidlines as mentioned below, do not hallucinate the answer.\"\"\"\n",
    "    \"\"\"The user preference is a table with their preferences denoted by like/dislike, and it is as follows:    userAction\tc1r\tc1g\tc1b\tc2r\tc2g\tc2b\tc3r\tc3g\tc3b\tc4r\tc4g\tc4b\n",
    "0\tdislike\t120\t26\t189\t120\t115\t204\t232\t2\t102\t197\t199\t154\n",
    "1\tdislike\t61\t164\t224\t50\t233\t171\t151\t206\t58\t117\t159\t95\n",
    "2\tLike\t232\t179\t112\t61\t240\t185\t51\t11\t253\t38\t129\t130\n",
    "3\tdislike\t100\t112\t183\t80\t186\t112\t1\t129\t219\t53\t86\t228\n",
    "4\tLike\t224\t128\t146\t125\t129\t52\t171\t217\t159\t197\t159\t246 \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Guidelines:\n",
    "    1. Give a single colour combination output. Try not to give any already mentioned colour from the preference data.\n",
    "    3. The output should be given as follows: \n",
    "        c1r : ## | c1g : ## | c1b: ## | respective colour name | respective colour hex-code\n",
    "        c2r : ## | c2g : ## | c2b: ## | respective colour name | respective colour hex-code\n",
    "        c3r : ## | c3g : ## | c3b: ## | respective colour name | respective colour hex-code\n",
    "        c4r : ## | c4g : ## | c4b: ## | respective colour name | respective colour hex-code\n",
    "    4. Finally give a message suggesting a creative name for the wallpaper based on the colours said by you.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\" You are part of the recommendations team. As a helpful assistant, aid in suggesting the colours for the wallpaper generator app, based on the user's preferences given. \"\"\"\n",
    "    \"\"\"Suggest new wallpaper colours for the user based on the given preferences. Apply the guidlines as mentioned below, do not hallucinate the answer.\"\"\"\n",
    "    \"\"\"The user preference is a table with their preferences denoted by like/dislike, and it is as follows:    \tuserAction\tc1r\tc1g\tc1b\tc2r\tc2g\tc2b\tc3r\tc3g\tc3b\tc4r\tc4g\tc4b\n",
    "0\tLike\t130\t0\t4\t217\t246\t254\t141\t102\t26\t136\t206\t14\n",
    "1\tLike\t41\t123\t204\t178\t62\t95\t230\t240\t51\t252\t95\t131\n",
    "2\tLike\t228\t150\t230\t236\t142\t170\t28\t35\t12\t159\t70\t186\n",
    "3\tdislike\t85\t27\t65\t169\t44\t61\t184\t244\t133\t27\t27\t107\n",
    "4\tLike\t83\t29\t189\t74\t127\t249\t246\t91\t216\t230\t189\t224 \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Guidelines:\n",
    "    1. Give a single colour combination output. Try not to give any already mentioned colour from the preference data.\n",
    "    3. The output should be given as follows: \n",
    "        c1r : ## | c1g : ## | c1b: ## | respective colour name | respective colour hex-code\n",
    "        c2r : ## | c2g : ## | c2b: ## | respective colour name | respective colour hex-code\n",
    "        c3r : ## | c3g : ## | c3b: ## | respective colour name | respective colour hex-code\n",
    "        c4r : ## | c4g : ## | c4b: ## | respective colour name | respective colour hex-code\n",
    "    4. Finally give a message suggesting a creative name for the wallpaper based on the colours said by you.\n",
    "    \"\"\",\n",
    "\n",
    "        \"\"\" You are part of the recommendations team. As a helpful assistant, aid in suggesting the colours for the wallpaper generator app, based on the user's preferences given. \"\"\"\n",
    "    \"\"\"Suggest new wallpaper colours for the user based on the given preferences. Apply the guidlines as mentioned below, do not hallucinate the answer.\"\"\"\n",
    "    \"\"\"The user preference is a table with their preferences denoted by like/dislike, and it is as follows:    userAction\tc1r\tc1g\tc1b\tc2r\tc2g\tc2b\tc3r\tc3g\tc3b\tc4r\tc4g\tc4b\n",
    "0\tdislike\t107\t54\t243\t63\t248\t130\t228\t50\t134\t20\t72\t166\n",
    "1\tLike\t131\t88\t59\t13\t241\t249\t8\t89\t52\t129\t83\t91\n",
    "2\tdislike\t187\t198\t171\t252\t7\t174\t34\t205\t80\t163\t49\t103\n",
    "3\tLike\t1\t253\t133\t53\t105\t3\t53\t220\t190\t145\t217\t43\n",
    "4\tLike\t201\t189\t227\t13\t94\t47\t14\t199\t205\t214\t251\t248\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Guidelines:\n",
    "    1. Give a single colour combination output. Try not to give any already mentioned colour from the preference data.\n",
    "    3. The output should be given as follows: \n",
    "        c1r : ## | c1g : ## | c1b: ## | respective colour name | respective colour hex-code\n",
    "        c2r : ## | c2g : ## | c2b: ## | respective colour name | respective colour hex-code\n",
    "        c3r : ## | c3g : ## | c3b: ## | respective colour name | respective colour hex-code\n",
    "        c4r : ## | c4g : ## | c4b: ## | respective colour name | respective colour hex-code\n",
    "    4. Finally give a message suggesting a creative name for the wallpaper based on the colours said by you.\n",
    "    \"\"\",\n",
    "\n",
    "        \"\"\" You are part of the recommendations team. As a helpful assistant, aid in suggesting the colours for the wallpaper generator app, based on the user's preferences given. \"\"\"\n",
    "    \"\"\"Suggest new wallpaper colours for the user based on the given preferences. Apply the guidlines as mentioned below, do not hallucinate the answer.\"\"\"\n",
    "    \"\"\"The user preference is a table with their preferences denoted by like/dislike, and it is as follows:    userAction\tc1r\tc1g\tc1b\tc2r\tc2g\tc2b\tc3r\tc3g\tc3b\tc4r\tc4g\tc4b\n",
    "0\tLike\t39\t212\t207\t236\t81\t110\t52\t23\t153\t216\t251\t187\n",
    "1\tLike\t236\t40\t156\t14\t44\t64\t88\t70\t8\t87\t128\t235\n",
    "2\tLike\t215\t62\t138\t242\t80\t135\t162\t162\t32\t122\t4\t233\n",
    "3\tdislike\t249\t40\t27\t134\t200\t71\t11\t161\t32\t47\t246\t150\n",
    "4\tLike\t215\t36\t98\t171\t103\t213\t218\t34\t192\t226\t100\t174\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Guidelines:\n",
    "    1. Give a single colour combination output. Try not to give any already mentioned colour from the preference data.\n",
    "    3. The output should be given as follows: \n",
    "        c1r : ## | c1g : ## | c1b: ## | respective colour name | respective colour hex-code\n",
    "        c2r : ## | c2g : ## | c2b: ## | respective colour name | respective colour hex-code\n",
    "        c3r : ## | c3g : ## | c3b: ## | respective colour name | respective colour hex-code\n",
    "        c4r : ## | c4g : ## | c4b: ## | respective colour name | respective colour hex-code\n",
    "    4. Finally give a message suggesting a creative name for the wallpaper based on the colours said by you.\n",
    "    \"\"\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2b09f7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "r1 = {\n",
    " 'userAction': {0: 'dislike'},\n",
    " 'c1r': {0: 100},\n",
    " 'c1g': {0: 200},\n",
    " 'c1b': {0: 255},\n",
    " 'c2r': {0: 255},\n",
    " 'c2g': {0: 100},\n",
    " 'c2b': {0: 100},\n",
    " 'c3r': {0: 200},\n",
    " 'c3g': {0: 200},\n",
    " 'c3b': {0: 255},\n",
    " 'c4r': {0: 100},\n",
    " 'c4g': {0: 100},\n",
    " 'c4b': {0: 255}\n",
    "}\n",
    "\n",
    "r2 = {\n",
    " 'userAction': {0: 'dislike'},\n",
    " 'c1r': {0: 240},\n",
    " 'c1g': {0: 185},\n",
    " 'c1b': {0: 51},\n",
    " 'c2r': {0: 125},\n",
    " 'c2g': {0: 129},\n",
    " 'c2b': {0: 52},\n",
    " 'c3r': {0: 171},\n",
    " 'c3g': {0: 217},\n",
    " 'c3b': {0: 159},\n",
    " 'c4r': {0: 159},\n",
    " 'c4g': {0: 197},\n",
    " 'c4b': {0: 159}\n",
    "}\n",
    "\n",
    "r3 = {\n",
    " 'userAction': {0: 'like'},\n",
    " 'c1r': {0: 178},\n",
    " 'c1g': {0: 62},\n",
    " 'c1b': {0: 95},\n",
    " 'c2r': {0: 236},\n",
    " 'c2g': {0: 142},\n",
    " 'c2b': {0: 170},\n",
    " 'c3r': {0: 228},\n",
    " 'c3g': {0: 150},\n",
    " 'c3b': {0: 230},\n",
    " 'c4r': {0: 83},\n",
    " 'c4g': {0: 29},\n",
    " 'c4b': {0: 189}\n",
    "}\n",
    "\n",
    "r4 = {\n",
    " 'userAction': {0: 'like'},\n",
    " 'c1r': {0: 240},\n",
    " 'c1g': {0: 240},\n",
    " 'c1b': {0: 150},\n",
    " 'c2r': {0: 150},\n",
    " 'c2g': {0: 100},\n",
    " 'c2b': {0: 20},\n",
    " 'c3r': {0: 200},\n",
    " 'c3g': {0: 255},\n",
    " 'c3b': {0: 200},\n",
    " 'c4r': {0: 255},\n",
    " 'c4g': {0: 20},\n",
    " 'c4b': {0: 20}\n",
    "}\n",
    "\n",
    "r5 = {\n",
    " 'userAction': {0: 'like'},\n",
    " 'c1r': {0: 123},\n",
    " 'c1g': {0: 234},\n",
    " 'c1b': {0: 255},\n",
    " 'c2r': {0: 255},\n",
    " 'c2g': {0: 204},\n",
    " 'c2b': {0: 153},\n",
    " 'c3r': {0: 255},\n",
    " 'c3g': {0: 102},\n",
    " 'c3b': {0: 0},\n",
    " 'c4r': {0: 255},\n",
    " 'c4g': {0: 0},\n",
    " 'c4b': {0: 128}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "57e5a917",
   "metadata": {},
   "outputs": [],
   "source": [
    "rejected = [r1, r2, r3, r4, r5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "493088dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame()\n",
    "data['prompt'] = prompts\n",
    "data['chosen'] = chosen\n",
    "data['rejected'] = rejected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "02f7c7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prompt</th>\n",
       "      <th>chosen</th>\n",
       "      <th>rejected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>You are part of the recommendations team. As ...</td>\n",
       "      <td>{'userAction': {0: 'dislike', 1: 'Like', 2: 'd...</td>\n",
       "      <td>{'userAction': {0: 'dislike'}, 'c1r': {0: 100}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You are part of the recommendations team. As ...</td>\n",
       "      <td>{'userAction': {0: 'dislike', 1: 'dislike', 2:...</td>\n",
       "      <td>{'userAction': {0: 'dislike'}, 'c1r': {0: 240}...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>You are part of the recommendations team. As ...</td>\n",
       "      <td>{'userAction': {0: 'Like', 1: 'Like', 2: 'Like...</td>\n",
       "      <td>{'userAction': {0: 'like'}, 'c1r': {0: 178}, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>You are part of the recommendations team. As ...</td>\n",
       "      <td>&lt;bound method DataFrame.to_dict of   userActio...</td>\n",
       "      <td>{'userAction': {0: 'like'}, 'c1r': {0: 240}, '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You are part of the recommendations team. As ...</td>\n",
       "      <td>{'userAction': {0: 'Like', 1: 'Like', 2: 'Like...</td>\n",
       "      <td>{'userAction': {0: 'like'}, 'c1r': {0: 123}, '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              prompt  \\\n",
       "0   You are part of the recommendations team. As ...   \n",
       "1   You are part of the recommendations team. As ...   \n",
       "2   You are part of the recommendations team. As ...   \n",
       "3   You are part of the recommendations team. As ...   \n",
       "4   You are part of the recommendations team. As ...   \n",
       "\n",
       "                                              chosen  \\\n",
       "0  {'userAction': {0: 'dislike', 1: 'Like', 2: 'd...   \n",
       "1  {'userAction': {0: 'dislike', 1: 'dislike', 2:...   \n",
       "2  {'userAction': {0: 'Like', 1: 'Like', 2: 'Like...   \n",
       "3  <bound method DataFrame.to_dict of   userActio...   \n",
       "4  {'userAction': {0: 'Like', 1: 'Like', 2: 'Like...   \n",
       "\n",
       "                                            rejected  \n",
       "0  {'userAction': {0: 'dislike'}, 'c1r': {0: 100}...  \n",
       "1  {'userAction': {0: 'dislike'}, 'c1r': {0: 240}...  \n",
       "2  {'userAction': {0: 'like'}, 'c1r': {0: 178}, '...  \n",
       "3  {'userAction': {0: 'like'}, 'c1r': {0: 240}, '...  \n",
       "4  {'userAction': {0: 'like'}, 'c1r': {0: 123}, '...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ea91c4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets\n",
    "pref_sample = datasets.Dataset.from_pandas(pd.DataFrame(data=data.astype(str)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c9f91703",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['prompt', 'chosen', 'rejected'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f0fee33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 39.22ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.18s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/KamalamSivakumar/pref_learning_sample/commit/53599b4dd585ad34a216029e175eed5c6e74bcf1', commit_message='Upload dataset', commit_description='', oid='53599b4dd585ad34a216029e175eed5c6e74bcf1', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref_sample.push_to_hub(\"KamalamSivakumar/pref_learning_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "03834b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 339/339 [00:00<00:00, 1.18MB/s]\n",
      "Downloading data: 100%|██████████| 24.3k/24.3k [00:00<00:00, 33.9kB/s]\n",
      "Generating train split: 100%|██████████| 5/5 [00:00<00:00, 173.59 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "pref_data = load_dataset(\"KamalamSivakumar/pref_learning_sample\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "39e190ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['prompt', 'chosen', 'rejected'],\n",
       "        num_rows: 5\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pref_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "1b14299a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.13it/s]\n",
      "WARNING:root:Some parameters are on the meta device device because they were offloaded to the disk and cpu.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoConfig, AutoModelForCausalLM\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.3\" #\"google/gemma-2b-it\" #\"google/gemma-2b\"\n",
    "tokenizer_id = \"mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    #huggingfacehub_api_token=access_token,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_id)\n",
    "tokenizer.padding_side = 'right' # to prevent warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9001e097",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kamalam.s\\AppData\\Local\\miniconda3\\envs\\rag\\Lib\\site-packages\\trl\\trainer\\orpo_trainer.py:209: UserWarning: `max_length` is not set in the ORPOConfig's init it will default to `512` by default, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kamalam.s\\AppData\\Local\\miniconda3\\envs\\rag\\Lib\\site-packages\\trl\\trainer\\orpo_trainer.py:218: UserWarning: `max_prompt_length` is not set in the ORPOConfig's init it will default to `128` by default, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "c:\\Users\\kamalam.s\\AppData\\Local\\miniconda3\\envs\\rag\\Lib\\site-packages\\trl\\trainer\\orpo_trainer.py:247: UserWarning: When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n",
      "  warnings.warn(\n",
      "Map: 100%|██████████| 5/5 [00:00<00:00, 27.54 examples/s]\n",
      "WARNING:accelerate.big_modeling:You shouldn't move a model that is dispatched using accelerate hooks.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "You can't move a model that has some modules offloaded to cpu or disk.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 7\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrl\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ORPOConfig, ORPOTrainer\n\u001b[0;32m      2\u001b[0m orpo_config \u001b[38;5;241m=\u001b[39m ORPOConfig(\n\u001b[0;32m      3\u001b[0m     beta\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.1\u001b[39m, \u001b[38;5;66;03m# the lambda/alpha hyperparameter in the paper/code\u001b[39;00m\n\u001b[0;32m      4\u001b[0m     output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morpo_results/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m )\n\u001b[1;32m----> 7\u001b[0m orpo_trainer \u001b[38;5;241m=\u001b[39m ORPOTrainer(\n\u001b[0;32m      8\u001b[0m     model,\n\u001b[0;32m      9\u001b[0m     args\u001b[38;5;241m=\u001b[39morpo_config,\n\u001b[0;32m     10\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mpref_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     11\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m     12\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\kamalam.s\\AppData\\Local\\miniconda3\\envs\\rag\\Lib\\site-packages\\trl\\trainer\\orpo_trainer.py:281\u001b[0m, in \u001b[0;36mORPOTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, callbacks, optimizers, preprocess_logits_for_metrics, peft_config, compute_metrics)\u001b[0m\n\u001b[0;32m    278\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m eval_dataset \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    279\u001b[0m         eval_dataset \u001b[38;5;241m=\u001b[39m eval_dataset\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtokenize_row, num_proc\u001b[38;5;241m=\u001b[39margs\u001b[38;5;241m.\u001b[39mdataset_num_proc)\n\u001b[1;32m--> 281\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m    282\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[0;32m    283\u001b[0m     args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m    284\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator,\n\u001b[0;32m    285\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_dataset,\n\u001b[0;32m    286\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39meval_dataset,\n\u001b[0;32m    287\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m    288\u001b[0m     model_init\u001b[38;5;241m=\u001b[39mmodel_init,\n\u001b[0;32m    289\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m    290\u001b[0m     callbacks\u001b[38;5;241m=\u001b[39mcallbacks,\n\u001b[0;32m    291\u001b[0m     optimizers\u001b[38;5;241m=\u001b[39moptimizers,\n\u001b[0;32m    292\u001b[0m     preprocess_logits_for_metrics\u001b[38;5;241m=\u001b[39mpreprocess_logits_for_metrics,\n\u001b[0;32m    293\u001b[0m )\n\u001b[0;32m    295\u001b[0m \u001b[38;5;66;03m# Add tags for models that have been loaded with the correct transformers version\u001b[39;00m\n\u001b[0;32m    296\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124madd_model_tags\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\kamalam.s\\AppData\\Local\\miniconda3\\envs\\rag\\Lib\\site-packages\\transformers\\trainer.py:528\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[1;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;66;03m# Bnb Quantized models doesn't support `.to` operation.\u001b[39;00m\n\u001b[0;32m    524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplace_model_on_device\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquantization_method\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m QuantizationMethod\u001b[38;5;241m.\u001b[39mBITS_AND_BYTES\n\u001b[0;32m    527\u001b[0m ):\n\u001b[1;32m--> 528\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_move_model_to_device(model, args\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    530\u001b[0m \u001b[38;5;66;03m# Force n_gpu to 1 to avoid DataParallel as MP will manage the GPUs\u001b[39;00m\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_model_parallel:\n",
      "File \u001b[1;32mc:\\Users\\kamalam.s\\AppData\\Local\\miniconda3\\envs\\rag\\Lib\\site-packages\\transformers\\trainer.py:775\u001b[0m, in \u001b[0;36mTrainer._move_model_to_device\u001b[1;34m(self, model, device)\u001b[0m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_move_model_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, device):\n\u001b[1;32m--> 775\u001b[0m     model \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m    776\u001b[0m     \u001b[38;5;66;03m# Moving a model to an XLA device disconnects the tied weights, so we have to retie them.\u001b[39;00m\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mparallel_mode \u001b[38;5;241m==\u001b[39m ParallelMode\u001b[38;5;241m.\u001b[39mTPU \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(model, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtie_weights\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\kamalam.s\\AppData\\Local\\miniconda3\\envs\\rag\\Lib\\site-packages\\accelerate\\big_modeling.py:455\u001b[0m, in \u001b[0;36mdispatch_model.<locals>.add_warning.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[0;32m    454\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m param\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmeta\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m--> 455\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt move a model that has some modules offloaded to cpu or disk.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: You can't move a model that has some modules offloaded to cpu or disk."
     ]
    }
   ],
   "source": [
    "from trl import ORPOConfig, ORPOTrainer\n",
    "orpo_config = ORPOConfig(\n",
    "    beta=0.1, # the lambda/alpha hyperparameter in the paper/code\n",
    "    output_dir = \"orpo_results/\"\n",
    ")\n",
    "\n",
    "orpo_trainer = ORPOTrainer(\n",
    "    model,\n",
    "    args=orpo_config,\n",
    "    train_dataset=pref_data['train'],\n",
    "    tokenizer=tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee401d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
